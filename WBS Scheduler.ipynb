{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-20T20:44:58.091371Z",
     "start_time": "2025-01-20T20:44:57.984098Z"
    }
   },
   "source": [
    "# Standard library imports\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Third-party imports\n",
    "import pulp\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # Make sure this is installed: pip install tqdm\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    " level=logging.INFO,\n",
    " format='%(asctime)s - %(levelname)s - %(message)s',\n",
    " handlers=[\n",
    " logging.FileHandler('scheduler.log'),\n",
    " logging.StreamHandler(sys.stdout)\n",
    " ]\n",
    ")\n",
    "\n",
    "@dataclass\n",
    "class ScenarioParams:\n",
    " \"\"\"Parameters defining a scenario\"\"\"\n",
    " resource_levels: Dict[str, int]\n",
    " sample_counts: Dict[str, int]\n",
    "\n",
    "@dataclass\n",
    "class ScenarioResult:\n",
    " \"\"\"Results from running a scenario\"\"\"\n",
    " params: ScenarioParams\n",
    " makespan: Optional[int]\n",
    " total_cost: float\n",
    " samples_per_year: int\n",
    " cost_per_sample: float\n",
    " resource_utilization: Dict[str, float]\n",
    " error: Optional[str] = None # Track any errors that occurred\n",
    "\n",
    "class SchedulerError(Exception):\n",
    " \"\"\"Custom exception for scheduler-specific errors\"\"\"\n",
    " pass\n",
    "\n",
    "def validate_scenario(scenario: dict, templates: List[dict]) -> None:\n",
    " \"\"\"Validate that a scenario has necessary resources for the templates.\"\"\"\n",
    " required_resources = set()\n",
    " for template in templates:\n",
    " for task in template:\n",
    " required_resources.add(task[\"resource\"])\n",
    " \n",
    " available_resources = set(scenario['resource_capacities'].keys())\n",
    " missing_resources = required_resources - available_resources\n",
    " \n",
    " if missing_resources:\n",
    " raise SchedulerError(\n",
    " f\"Missing required resources: {missing_resources}. \"\n",
    " \"These resources are needed for tasks in the templates.\"\n",
    " )\n",
    "\n",
    "def process_scenario(scenario: dict, templates: List[dict], resource_unit_costs: Dict[str, float], \n",
    " scenario_num: int, total_scenarios: int) -> dict:\n",
    " \"\"\"Process a single scenario with error handling.\"\"\"\n",
    " try:\n",
    " # Validate scenario\n",
    " validate_scenario(scenario, templates)\n",
    " \n",
    " all_tasks = []\n",
    " scenario_values = list(scenario.values())[:-1]\n",
    " for template, count, prefix in zip(templates, scenario_values, [\"MET_\", \"CER_\", \"COMP_\", \"POLY_\"]):\n",
    " all_tasks.extend(replicate_wbs_optimized(template, count, prefix))\n",
    " \n",
    " makespan, starts = schedule_wbs_discrete_optimized(\n",
    " tasks=all_tasks,\n",
    " resource_capacities=scenario['resource_capacities']\n",
    " )\n",
    " \n",
    " if makespan is None:\n",
    " raise SchedulerError(\"Failed to find feasible schedule\")\n",
    " \n",
    " total_cost, usage = compute_resource_usage_cost(\n",
    " all_tasks, starts, resource_unit_costs, makespan\n",
    " )\n",
    " \n",
    " return {\n",
    " 'scenario': scenario,\n",
    " 'makespan': makespan,\n",
    " 'total_cost': total_cost,\n",
    " 'usage': usage,\n",
    " 'error': None\n",
    " }\n",
    " \n",
    " except SchedulerError as e:\n",
    " logging.warning(f\"Scenario {scenario_num}/{total_scenarios} failed: {str(e)}\")\n",
    " return {\n",
    " 'scenario': scenario,\n",
    " 'makespan': None,\n",
    " 'total_cost': 0,\n",
    " 'usage': {},\n",
    " 'error': str(e)\n",
    " }\n",
    " except Exception as e:\n",
    " logging.error(f\"Unexpected error in scenario {scenario_num}/{total_scenarios}: {str(e)}\")\n",
    " return {\n",
    " 'scenario': scenario,\n",
    " 'makespan': None,\n",
    " 'total_cost': 0,\n",
    " 'usage': {},\n",
    " 'error': f\"Unexpected error: {str(e)}\"\n",
    " }\n",
    "\n",
    "def run_scenarios_optimized(scenarios: List[dict], templates: List[dict], \n",
    " resource_unit_costs: Dict[str, float]) -> List[dict]:\n",
    " \"\"\"Run all scenarios in parallel with progress tracking.\"\"\"\n",
    " total_scenarios = len(scenarios)\n",
    " completed = 0\n",
    " results = []\n",
    " \n",
    " logging.info(f\"Starting optimization of {total_scenarios} scenarios\")\n",
    " start_time = time.time()\n",
    " \n",
    " with ThreadPoolExecutor() as executor:\n",
    " # Submit all scenarios\n",
    " future_to_scenario = {\n",
    " executor.submit(\n",
    " process_scenario, \n",
    " scenario, \n",
    " templates, \n",
    " resource_unit_costs,\n",
    " i + 1,\n",
    " total_scenarios\n",
    " ): i for i, scenario in enumerate(scenarios)\n",
    " }\n",
    " \n",
    " # Process completed scenarios with progress bar\n",
    " with tqdm(total=total_scenarios, desc=\"Processing scenarios\") as pbar:\n",
    " for future in as_completed(future_to_scenario):\n",
    " scenario_idx = future_to_scenario[future]\n",
    " try:\n",
    " result = future.result()\n",
    " results.append(result)\n",
    " completed += 1\n",
    " \n",
    " # Update progress every 50 scenarios\n",
    " if completed % 50 == 0:\n",
    " elapsed = time.time() - start_time\n",
    " rate = completed / elapsed\n",
    " eta = (total_scenarios - completed) / rate if rate > 0 else 0\n",
    " logging.info(\n",
    " f\"Completed {completed}/{total_scenarios} scenarios \"\n",
    " f\"({completed/total_scenarios*100:.1f}%) \"\n",
    " f\"Rate: {rate:.1f} scenarios/sec \"\n",
    " f\"ETA: {eta/60:.1f} minutes\"\n",
    " )\n",
    " \n",
    " except Exception as e:\n",
    " logging.error(f\"Error processing scenario {scenario_idx}: {str(e)}\")\n",
    " results.append({\n",
    " 'scenario': scenarios[scenario_idx],\n",
    " 'makespan': None,\n",
    " 'total_cost': 0,\n",
    " 'usage': {},\n",
    " 'error': str(e)\n",
    " })\n",
    " \n",
    " pbar.update(1)\n",
    " \n",
    " # Final summary\n",
    " end_time = time.time()\n",
    " total_time = end_time - start_time\n",
    " successful = sum(1 for r in results if r['error'] is None)\n",
    " \n",
    " logging.info(\n",
    " f\"\\nCompleted {total_scenarios} scenarios in {total_time:.1f} seconds\\n\"\n",
    " f\"Successful: {successful}/{total_scenarios} ({successful/total_scenarios*100:.1f}%)\\n\"\n",
    " f\"Failed: {total_scenarios-successful}/{total_scenarios} \"\n",
    " f\"({(total_scenarios-successful)/total_scenarios*100:.1f}%)\"\n",
    " )\n",
    " \n",
    " return results\n",
    "\n",
    "def generate_scenarios(\n",
    " resource_ranges: Dict[str, Tuple[int, int]], # e.g., {\"Admin\": (1,3)}\n",
    " sample_ranges: Dict[str, Tuple[int, int]], # e.g., {\"metals\": (0,10)}\n",
    " step_sizes: Dict[str, int] = None # Optional step sizes\n",
    ") -> List[ScenarioParams]:\n",
    " \"\"\"Generate all scenario combinations within given ranges\"\"\"\n",
    " if step_sizes is None:\n",
    " step_sizes = {k: 1 for k in {**resource_ranges, **sample_ranges}.keys()}\n",
    " \n",
    " # Generate resource level combinations\n",
    " resource_values = [\n",
    " range(start, end + 1, step_sizes.get(resource, 1))\n",
    " for resource, (start, end) in resource_ranges.items()\n",
    " ]\n",
    " resource_combinations = list(itertools.product(*resource_values))\n",
    " \n",
    " # Generate sample count combinations\n",
    " sample_values = [\n",
    " range(start, end + 1, step_sizes.get(sample_type, 1))\n",
    " for sample_type, (start, end) in sample_ranges.items()\n",
    " ]\n",
    " sample_combinations = list(itertools.product(*sample_values))\n",
    " \n",
    " # Create all possible combinations\n",
    " scenarios = []\n",
    " for res_combo in resource_combinations:\n",
    " for sample_combo in sample_combinations:\n",
    " resource_dict = dict(zip(resource_ranges.keys(), res_combo))\n",
    " sample_dict = dict(zip(sample_ranges.keys(), sample_combo))\n",
    " scenarios.append(ScenarioParams(\n",
    " resource_levels=resource_dict,\n",
    " sample_counts=sample_dict\n",
    " ))\n",
    " \n",
    " return scenarios\n",
    "############################\n",
    "# Critical Path Calculation\n",
    "############################\n",
    "def compute_earliest_starts(tasks):\n",
    " \"\"\"Compute the earliest possible start times for each task using the critical path method.\"\"\"\n",
    " earliest_starts = {}\n",
    " task_dict = {t[\"id\"]: t for t in tasks}\n",
    "\n",
    " def get_earliest_start(task_id, memo=None):\n",
    " if memo is None:\n",
    " memo = {}\n",
    " if task_id in memo:\n",
    " return memo[task_id]\n",
    " \n",
    " task = task_dict[task_id]\n",
    " if not task[\"dependencies\"]: # No dependencies\n",
    " memo[task_id] = 0\n",
    " return 0\n",
    " \n",
    " max_pred_finish = 0\n",
    " for pred_id in task[\"dependencies\"]:\n",
    " if pred_id not in task_dict:\n",
    " raise ValueError(f\"Task {task_id} references missing dependency {pred_id}\")\n",
    " pred_start = get_earliest_start(pred_id, memo)\n",
    " pred_finish = pred_start + task_dict[pred_id][\"duration\"]\n",
    " max_pred_finish = max(max_pred_finish, pred_finish)\n",
    " \n",
    " memo[task_id] = max_pred_finish\n",
    " return max_pred_finish\n",
    "\n",
    " for task in tasks:\n",
    " earliest_starts[task[\"id\"]] = get_earliest_start(task[\"id\"])\n",
    " \n",
    " return earliest_starts\n",
    "\n",
    "############################\n",
    "# Optimized Discrete Scheduler\n",
    "############################\n",
    "def schedule_wbs_discrete_optimized(tasks, resource_capacities, time_horizon=None):\n",
    " \"\"\"Schedule tasks with dependencies and resource constraints in discrete time using ILP.\"\"\"\n",
    " # Compute earliest start times and critical path\n",
    " earliest_starts = compute_earliest_starts(tasks)\n",
    " \n",
    " # Compute tighter time horizon\n",
    " if time_horizon is None:\n",
    " time_horizon = max(\n",
    " earliest_starts[t[\"id\"]] + t[\"duration\"] for t in tasks\n",
    " )\n",
    " \n",
    " # Quick lookups\n",
    " task_ids = [t[\"id\"] for t in tasks]\n",
    " durations = {t[\"id\"]: t[\"duration\"] for t in tasks}\n",
    " dependencies = {t[\"id\"]: t[\"dependencies\"] for t in tasks}\n",
    " resources = {t[\"id\"]: t[\"resource\"] for t in tasks}\n",
    " \n",
    " # Create the ILP model\n",
    " model = pulp.LpProblem(\"Discrete_WBS_Scheduling\", pulp.LpMinimize)\n",
    " \n",
    " # Decision variables: Start times\n",
    " x = {}\n",
    " for i in task_ids:\n",
    " for t in range(earliest_starts[i], time_horizon - durations[i] + 1):\n",
    " x[i, t] = pulp.LpVariable(f\"start_{i}_{t}\", cat=pulp.LpBinary)\n",
    " \n",
    " # Makespan variable\n",
    " T = pulp.LpVariable(\"Makespan\", lowBound=0, upBound=time_horizon, cat=pulp.LpInteger)\n",
    " \n",
    " # Constraints\n",
    " # 1. Each task must start exactly once\n",
    " for i in task_ids:\n",
    " model += pulp.lpSum(x[i, t] for t in range(earliest_starts[i], time_horizon - durations[i] + 1)) == 1\n",
    " \n",
    " # 2. Precedence constraints\n",
    " for i in task_ids:\n",
    " for j in dependencies[i]:\n",
    " dur_j = durations[j]\n",
    " for t_j in range(earliest_starts[j], time_horizon - dur_j + 1):\n",
    " finish_j = t_j + dur_j\n",
    " for t_i in range(finish_j, time_horizon - durations[i] + 1):\n",
    " if (j, t_j) in x and (i, t_i) in x:\n",
    " model += x[j, t_j] + x[i, t_i] <= 1\n",
    " \n",
    " # 3. Resource constraints\n",
    " resource_tasks = defaultdict(list)\n",
    " for t in tasks:\n",
    " resource_tasks[t[\"resource\"]].append(t[\"id\"])\n",
    " \n",
    " for r, cap in resource_capacities.items():\n",
    " tasks_r = resource_tasks[r]\n",
    " if not tasks_r:\n",
    " continue\n",
    " for u in range(time_horizon):\n",
    " active_sum = []\n",
    " for i in tasks_r:\n",
    " dur_i = durations[i]\n",
    " for t_val in range(earliest_starts[i], time_horizon - dur_i + 1):\n",
    " if t_val <= u < t_val + dur_i and (i, t_val) in x:\n",
    " active_sum.append(x[i, t_val])\n",
    " if active_sum:\n",
    " model += pulp.lpSum(active_sum) <= cap\n",
    " \n",
    " # 4. Makespan constraints\n",
    " for i in task_ids:\n",
    " for t_val in range(earliest_starts[i], time_horizon - durations[i] + 1):\n",
    " if (i, t_val) in x:\n",
    " model += T >= t_val + durations[i] * x[i, t_val]\n",
    " \n",
    " # Objective: Minimize makespan\n",
    " model += T, \"Minimize_Makespan\"\n",
    " \n",
    " # Solve\n",
    " solver = pulp.PULP_CBC_CMD(msg=0, timeLimit=300)\n",
    " model.solve(solver)\n",
    " \n",
    " # Extract solution\n",
    " start_times = {}\n",
    " for i in task_ids:\n",
    " for t_val in range(earliest_starts[i], time_horizon - durations[i] + 1):\n",
    " if (i, t_val) in x and pulp.value(x[i, t_val]) > 0.5:\n",
    " start_times[i] = t_val\n",
    " break\n",
    " \n",
    " makespan_value = int(round(pulp.value(T))) if pulp.value(T) is not None else None\n",
    " return makespan_value, start_times\n",
    "\n",
    "############################\n",
    "# Replicate WBS\n",
    "############################\n",
    "def replicate_wbs_optimized(template, count, prefix):\n",
    " \"\"\"Replicate a WBS template multiple times.\"\"\"\n",
    " if count == 0:\n",
    " return []\n",
    " replicated_tasks = []\n",
    " for n in range(count):\n",
    " instance_suffix = f\"_{n}\"\n",
    " for task in template:\n",
    " replicated_tasks.append({\n",
    " \"id\": f\"{prefix}{task['id']}{instance_suffix}\",\n",
    " \"duration\": task[\"duration\"],\n",
    " \"dependencies\": [f\"{prefix}{dep}{instance_suffix}\" for dep in task[\"dependencies\"]],\n",
    " \"resource\": task[\"resource\"]\n",
    " })\n",
    " return replicated_tasks\n",
    "\n",
    "############################\n",
    "# Resource Usage and Cost\n",
    "############################\n",
    "def compute_resource_usage_cost(tasks, start_times, resource_unit_costs, makespan):\n",
    " \"\"\"Calculate resource usage and cost over the makespan.\"\"\"\n",
    " resource_usage = defaultdict(lambda: defaultdict(int))\n",
    " for task_id, start_time in start_times.items():\n",
    " task = next(t for t in tasks if t[\"id\"] == task_id)\n",
    " for t in range(start_time, start_time + task[\"duration\"]):\n",
    " if t <= makespan:\n",
    " resource_usage[task[\"resource\"]][t] += 1\n",
    " \n",
    " total_cost = sum(\n",
    " usage * resource_unit_costs.get(r, 0.0)\n",
    " for r, times in resource_usage.items()\n",
    " for usage in times.values()\n",
    " )\n",
    " return total_cost, dict(resource_usage)\n",
    "\n",
    "############################\n",
    "# Run Scenarios\n",
    "############################\n",
    "def process_scenario(scenario, templates, resource_unit_costs):\n",
    " \"\"\"Process a single scenario.\"\"\"\n",
    " all_tasks = []\n",
    " # Convert dict_values to list before slicing\n",
    " scenario_values = list(scenario.values())[:-1]\n",
    " for template, count, prefix in zip(templates, scenario_values, [\"MET_\", \"CER_\", \"COMP_\", \"POLY_\"]):\n",
    " all_tasks.extend(replicate_wbs_optimized(template, count, prefix))\n",
    " \n",
    " makespan, starts = schedule_wbs_discrete_optimized(\n",
    " tasks=all_tasks,\n",
    " resource_capacities=scenario['resource_capacities']\n",
    " )\n",
    " total_cost, usage = compute_resource_usage_cost(all_tasks, starts, resource_unit_costs, makespan)\n",
    " return {'scenario': scenario, 'makespan': makespan, 'total_cost': total_cost, 'usage': usage}\n",
    "\n",
    "def process_and_save_results(scenarios: List[ScenarioParams], \n",
    " raw_results: List[dict], \n",
    " output_file: str) -> pd.DataFrame:\n",
    " \"\"\"\n",
    " Process raw scheduling results into final format and save to CSV.\n",
    " \n",
    " Args:\n",
    " scenarios: List of original ScenarioParams objects\n",
    " raw_results: List of raw results from scheduler\n",
    " output_file: Path to save CSV output\n",
    " \n",
    " Returns:\n",
    " DataFrame containing processed results\n",
    " \"\"\"\n",
    " final_results = []\n",
    " \n",
    " for scenario, result in zip(scenarios, raw_results):\n",
    " if result['error'] is not None:\n",
    " # Handle failed scenarios\n",
    " final_results.append(ScenarioResult(\n",
    " params=scenario,\n",
    " makespan=None,\n",
    " total_cost=0.0,\n",
    " samples_per_year=0,\n",
    " cost_per_sample=0.0,\n",
    " resource_utilization={},\n",
    " error=result['error']\n",
    " ))\n",
    " continue\n",
    " \n",
    " # Calculate annual throughput (assuming makespan is in days)\n",
    " total_samples = sum(scenario.sample_counts.values())\n",
    " if result['makespan'] > 0:\n",
    " samples_per_year = int(365 * total_samples / result['makespan'])\n",
    " else:\n",
    " samples_per_year = 0\n",
    " \n",
    " # Calculate cost per sample\n",
    " if total_samples > 0:\n",
    " cost_per_sample = result['total_cost'] / total_samples\n",
    " else:\n",
    " cost_per_sample = 0.0\n",
    " \n",
    " # Calculate resource utilization\n",
    " utilization = {}\n",
    " for resource, usage_dict in result['usage'].items():\n",
    " max_possible_usage = scenario.resource_levels[resource] * result['makespan']\n",
    " total_usage = sum(usage_dict.values())\n",
    " if max_possible_usage > 0:\n",
    " utilization[resource] = total_usage / max_possible_usage\n",
    " else:\n",
    " utilization[resource] = 0.0\n",
    " \n",
    " final_results.append(ScenarioResult(\n",
    " params=scenario,\n",
    " makespan=result['makespan'],\n",
    " total_cost=result['total_cost'],\n",
    " samples_per_year=samples_per_year,\n",
    " cost_per_sample=cost_per_sample,\n",
    " resource_utilization=utilization,\n",
    " error=None\n",
    " ))\n",
    " \n",
    " # Convert to DataFrame for saving\n",
    " records = []\n",
    " for result in final_results:\n",
    " record = {\n",
    " # Resource levels\n",
    " **{f\"resource_{k}\": v for k, v in result.params.resource_levels.items()},\n",
    " # Sample counts\n",
    " **{f\"samples_{k}\": v for k, v in result.params.sample_counts.items()},\n",
    " # Results\n",
    " \"makespan\": result.makespan,\n",
    " \"total_cost\": result.total_cost,\n",
    " \"samples_per_year\": result.samples_per_year,\n",
    " \"cost_per_sample\": result.cost_per_sample,\n",
    " # Resource utilization\n",
    " **{f\"utilization_{k}\": v for k, v in result.resource_utilization.items()},\n",
    " # Error tracking\n",
    " \"error\": result.error\n",
    " }\n",
    " records.append(record)\n",
    " \n",
    " # Create DataFrame and save\n",
    " df = pd.DataFrame(records)\n",
    " df.to_csv(output_file, index=False)\n",
    " \n",
    " # Log summary statistics\n",
    " successful = df['error'].isna().sum()\n",
    " total = len(df)\n",
    " logging.info(f\"\\nResults Summary:\")\n",
    " logging.info(f\"Total scenarios processed: {total}\")\n",
    " logging.info(f\"Successful scenarios: {successful} ({successful/total*100:.1f}%)\")\n",
    " logging.info(f\"Failed scenarios: {total-successful} ({(total-successful)/total*100:.1f}%)\")\n",
    " if successful > 0:\n",
    " logging.info(f\"Average samples per year: {df['samples_per_year'].mean():.1f}\")\n",
    " logging.info(f\"Average cost per sample: ${df['cost_per_sample'].mean():.2f}\")\n",
    " logging.info(f\"Results saved to: {output_file}\")\n",
    " \n",
    " return df\n",
    "\n",
    "def run_capacity_analysis(\n",
    " templates: List[dict],\n",
    " resource_ranges: Dict[str, Tuple[int, int]],\n",
    " sample_ranges: Dict[str, Tuple[int, int]],\n",
    " resource_unit_costs: Dict[str, float],\n",
    " step_sizes: Dict[str, int] = None,\n",
    " output_file: str = \"capacity_results.csv\"\n",
    ") -> pd.DataFrame:\n",
    " \"\"\"Run complete capacity analysis across all scenarios.\"\"\"\n",
    " # Generate scenarios\n",
    " scenarios = generate_scenarios(resource_ranges, sample_ranges, step_sizes)\n",
    " logging.info(f\"Generated {len(scenarios)} scenarios to evaluate\")\n",
    " \n",
    " # Convert scenarios to scheduler format\n",
    " scheduler_scenarios = []\n",
    " for scenario in scenarios:\n",
    " scheduler_scenario = {\n",
    " \"metals_count\": scenario.sample_counts.get(\"metals\", 0),\n",
    " \"ceramics_count\": scenario.sample_counts.get(\"ceramics\", 0),\n",
    " \"composites_count\": scenario.sample_counts.get(\"composites\", 0),\n",
    " \"polymer_count\": scenario.sample_counts.get(\"polymers\", 0),\n",
    " \"resource_capacities\": scenario.resource_levels\n",
    " }\n",
    " scheduler_scenarios.append(scheduler_scenario)\n",
    " \n",
    " # Run scenarios\n",
    " results = run_scenarios_optimized(scheduler_scenarios, templates, resource_unit_costs)\n",
    " \n",
    " # Convert results to ScenarioResult format and save\n",
    " final_results = process_and_save_results(scenarios, results, output_file)\n",
    " \n",
    " return final_results\n",
    "\n",
    "def run_scenarios_optimized(scenarios, templates, resource_unit_costs):\n",
    " \"\"\"Run all scenarios in parallel.\"\"\"\n",
    " with ThreadPoolExecutor() as executor:\n",
    " results = executor.map(lambda s: process_scenario(s, templates, resource_unit_costs), scenarios)\n",
    " return list(results)\n",
    "\n",
    "\n",
    "\n",
    "def save_results(results: List[ScenarioResult], filename: str):\n",
    " \"\"\"Save scenario results to CSV\"\"\"\n",
    " records = []\n",
    " for result in results:\n",
    " record = {\n",
    " # Resource levels\n",
    " **{f\"resource_{k}\": v for k, v in result.params.resource_levels.items()},\n",
    " # Sample counts\n",
    " **{f\"samples_{k}\": v for k, v in result.params.sample_counts.items()},\n",
    " # Results\n",
    " \"makespan\": result.makespan,\n",
    " \"total_cost\": result.total_cost,\n",
    " \"samples_per_year\": result.samples_per_year,\n",
    " \"cost_per_sample\": result.cost_per_sample,\n",
    " # Resource utilization\n",
    " **{f\"utilization_{k}\": v for k, v in result.resource_utilization.items()}\n",
    " }\n",
    " records.append(record)\n",
    " \n",
    " df = pd.DataFrame(records)\n",
    " df.to_csv(filename, index=False)\n",
    " return df\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    " # Define ranges to test\n",
    " resource_ranges = {\n",
    " \"Admin\": (1, 3),\n",
    " \"LabTech\": (1, 2),\n",
    " \"MaterialsScientist\": (1, 2)\n",
    " }\n",
    " \n",
    " sample_ranges = {\n",
    " \"metals\": (0, 10),\n",
    " \"ceramics\": (0, 10),\n",
    " \"composites\": (0, 8),\n",
    " \"polymers\": (0, 8)\n",
    " }\n",
    " \n",
    " # Optional: Define step sizes to reduce combinations\n",
    " step_sizes = {\n",
    " \"metals\": 2,\n",
    " \"ceramics\": 2,\n",
    " \"composites\": 2,\n",
    " \"polymers\": 2\n",
    " }\n",
    " \n",
    " # Generate scenarios\n",
    " scenarios = generate_scenarios(resource_ranges, sample_ranges, step_sizes)\n",
    " print(f\"Generated {len(scenarios)} scenarios\")\n",
    " \n",
    " # These would be your actual results after running the scenarios\n",
    " example_result = ScenarioResult(\n",
    " params=scenarios[0],\n",
    " makespan=100,\n",
    " total_cost=50000.0,\n",
    " samples_per_year=45,\n",
    " cost_per_sample=1111.11,\n",
    " resource_utilization={\"Admin\": 0.85, \"LabTech\": 0.92, \"MaterialsScientist\": 0.75}\n",
    " )\n",
    " \n",
    " # Save results\n",
    " save_results([example_result], \"scenario_results.csv\")\n",
    " \n",
    "import pulp\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# [Previous scenario generation code remains the same through the classes]\n",
    "@dataclass\n",
    "class ScenarioParams:\n",
    " resource_levels: Dict[str, int]\n",
    " sample_counts: Dict[str, int]\n",
    "\n",
    "@dataclass\n",
    "class ScenarioResult:\n",
    " params: ScenarioParams\n",
    " makespan: int\n",
    " total_cost: float\n",
    " samples_per_year: int\n",
    " cost_per_sample: float\n",
    " resource_utilization: Dict[str, float]\n",
    "\n",
    "def run_capacity_analysis(\n",
    " templates: List[dict],\n",
    " resource_ranges: Dict[str, Tuple[int, int]],\n",
    " sample_ranges: Dict[str, Tuple[int, int]],\n",
    " resource_unit_costs: Dict[str, float],\n",
    " step_sizes: Dict[str, int] = None, # Optional - set to None to use step size of 1\n",
    " output_file: str = \"capacity_results.csv\"\n",
    ") -> pd.DataFrame:\n",
    " \"\"\"\n",
    " Run complete capacity analysis across all scenarios.\n",
    " \n",
    " Args:\n",
    " templates: List of WBS templates [metals, ceramics, composites, polymers]\n",
    " resource_ranges: Dict of resource min/max e.g., {\"Admin\": (1,3)}\n",
    " sample_ranges: Dict of sample type min/max e.g., {\"metals\": (0,10)}\n",
    " resource_unit_costs: Dict of costs per resource unit\n",
    " step_sizes: Dict of step sizes for each parameter (optional)\n",
    " output_file: Where to save results\n",
    " \"\"\"\n",
    " # Generate scenarios\n",
    " scenarios = generate_scenarios(resource_ranges, sample_ranges, step_sizes)\n",
    " print(f\"Generated {len(scenarios)} scenarios to evaluate\")\n",
    " \n",
    " # Convert scenarios to format needed by scheduler\n",
    " scheduler_scenarios = []\n",
    " for scenario in scenarios:\n",
    " scheduler_scenario = {\n",
    " \"metals_count\": scenario.sample_counts.get(\"metals\", 0),\n",
    " \"ceramics_count\": scenario.sample_counts.get(\"ceramics\", 0),\n",
    " \"composites_count\": scenario.sample_counts.get(\"composites\", 0),\n",
    " \"polymer_count\": scenario.sample_counts.get(\"polymers\", 0),\n",
    " \"resource_capacities\": scenario.resource_levels\n",
    " }\n",
    " scheduler_scenarios.append(scheduler_scenario)\n",
    " \n",
    " # Run scenarios\n",
    " start_time = time.time()\n",
    " results = run_scenarios_optimized(scheduler_scenarios, templates, resource_unit_costs)\n",
    " end_time = time.time()\n",
    " print(f\"Completed {len(scenarios)} scenarios in {end_time - start_time:.1f} seconds\")\n",
    " \n",
    " # Convert results to ScenarioResult format\n",
    " final_results = []\n",
    " for scenario, result in zip(scenarios, results):\n",
    " if result['makespan'] is None: # Handle infeasible scenarios\n",
    " continue\n",
    " \n",
    " # Calculate samples per year (assuming makespan is in days)\n",
    " total_samples = sum(scenario.sample_counts.values())\n",
    " samples_per_year = int(365 * total_samples / result['makespan'])\n",
    " \n",
    " # Calculate cost per sample\n",
    " cost_per_sample = result['total_cost'] / total_samples if total_samples > 0 else 0\n",
    " \n",
    " # Calculate resource utilization\n",
    " utilization = {}\n",
    " for resource, usage_dict in result['usage'].items():\n",
    " max_possible_usage = scenario.resource_levels[resource] * result['makespan']\n",
    " total_usage = sum(usage_dict.values())\n",
    " utilization[resource] = total_usage / max_possible_usage if max_possible_usage > 0 else 0\n",
    " \n",
    " final_results.append(ScenarioResult(\n",
    " params=scenario,\n",
    " makespan=result['makespan'],\n",
    " total_cost=result['total_cost'],\n",
    " samples_per_year=samples_per_year,\n",
    " cost_per_sample=cost_per_sample,\n",
    " resource_utilization=utilization\n",
    " ))\n",
    " \n",
    " # Save results\n",
    " df = save_results(final_results, output_file)\n",
    " return df\n",
    "\n",
    "#\n",
    "# ============= YOUR WBS TEMPLATES =============\n",
    "#\n",
    "metals_template = [\n",
    " # ------ Sample Management ------\n",
    " {\"id\": \"1.1\", \"name\": \"Receive and Log Samples\", \"duration\": 4, \"dependencies\": [], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.2\", \"name\": \"Assign Unique Identifiers\", \"duration\": 2, \"dependencies\": [\"1.1\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.3\", \"name\": \"Photograph Initial Condition\", \"duration\": 2, \"dependencies\": [\"1.2\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"1.4\", \"name\": \"Write Analysis Plan\", \"duration\": 3, \"dependencies\": [\"1.3\"], \"resource\": \"Materials Scientist (Metals)\"},\n",
    " {\"id\": \"1.5\", \"name\": \"Store Samples Appropriately\", \"duration\": 1, \"dependencies\": [\"1.4\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.6\", \"name\": \"Document Chain of Custody\", \"duration\": 1, \"dependencies\": [\"1.5\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " # ------ Sample Preparation ------\n",
    " {\"id\": \"2.1\", \"name\": \"Cut Subsamples for Mounting\", \"duration\": 3, \"dependencies\": [\"1.6\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.2\", \"name\": \"Cut Subsamples for Light El.\", \"duration\": 3, \"dependencies\": [\"1.6\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.3\", \"name\": \"Cut for ICP-OES/ICP-MS\", \"duration\": 3, \"dependencies\": [\"1.6\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.4\", \"name\": \"Clean Cut Subsamples\", \"duration\": 2, \"dependencies\": [\"2.1\",\"2.2\",\"2.3\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.5\", \"name\": \"Mount Subsample in Epoxy\", \"duration\": 3, \"dependencies\": [\"2.1\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.6\", \"name\": \"Grind & Polish Mounted Subsmpl\", \"duration\": 4, \"dependencies\": [\"2.5\"], \"resource\": \"Materials Scientist (Metals)\"},\n",
    " {\"id\": \"2.7\", \"name\": \"Digest Sample with Acid/MW\", \"duration\": 4, \"dependencies\": [\"2.4\"], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " {\"id\": \"2.8\", \"name\": \"Prep ICP Standards/Blanks\", \"duration\": 2, \"dependencies\": [], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " {\"id\": \"2.9\", \"name\": \"Coat Sample for SEM/EBSD\", \"duration\": 2, \"dependencies\": [\"2.6\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.10\",\"name\": \"Label & Catalog Prepared Smpls\", \"duration\": 2, \"dependencies\": [\"2.3\",\"2.6\",\"2.7\",\"2.9\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " # ------ Sample Analysis ------\n",
    " {\"id\": \"3.1\", \"name\": \"Optical Microscope\", \"duration\": 2, \"dependencies\": [\"2.6\"], \"resource\": \"Materials Scientist (Metals)\"},\n",
    " {\"id\": \"3.2\", \"name\": \"SEM Imaging\", \"duration\": 4, \"dependencies\": [\"2.9\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"3.3\", \"name\": \"SEM-EDS Bulk Composition\", \"duration\": 4, \"dependencies\": [\"3.2\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"3.4\", \"name\": \"SEM-EBSD Grain Analysis\", \"duration\": 4, \"dependencies\": [\"3.2\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"3.5\", \"name\": \"Density via Pycnometer\", \"duration\": 3, \"dependencies\": [\"2.4\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"3.6\", \"name\": \"Composition XRF\", \"duration\": 3, \"dependencies\": [\"2.4\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"3.7\", \"name\": \"Composition SparkOES\", \"duration\": 3, \"dependencies\": [\"2.6\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"3.8\", \"name\": \"Light Elements (CHNOS)\", \"duration\": 3, \"dependencies\": [\"2.4\"], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " {\"id\": \"3.9\", \"name\": \"Hardness Microindentation\", \"duration\": 3, \"dependencies\": [\"2.6\"], \"resource\": \"Materials Scientist (Metals)\"},\n",
    " {\"id\": \"3.10\",\"name\": \"ICP-MS/ICP-OES\", \"duration\": 8, \"dependencies\": [], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " # ------ Data Analysis ------\n",
    " {\"id\": \"4.1\", \"name\": \"Compile Analytical Results\", \"duration\": 2, \"dependencies\": [\"3.1\",\"3.2\",\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\",\"3.8\",\"3.9\"], \"resource\": \"Materials Scientist (Metals)\"},\n",
    " {\"id\": \"4.2\", \"name\": \"Cross-Validate Composition\", \"duration\": 6, \"dependencies\": [\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\",\"3.8\",\"3.9\"], \"resource\": \"Materials Scientist (Metals)\"},\n",
    " {\"id\": \"4.3\", \"name\": \"DB Match or Similar Alloy\", \"duration\": 4, \"dependencies\": [], \"resource\": \"Materials Scientist (Metals)\"},\n",
    " {\"id\": \"4.4\", \"name\": \"Prepare Final Figures\", \"duration\": 3, \"dependencies\": [\"4.3\"], \"resource\": \"Materials Scientist (Metals)\"},\n",
    " {\"id\": \"4.5\", \"name\": \"Perform Peer Review\", \"duration\": 2, \"dependencies\": [\"4.4\"], \"resource\": \"Materials Scientist (Metals)\"},\n",
    " {\"id\": \"4.6\", \"name\": \"QA Review of Data/Results\", \"duration\": 1, \"dependencies\": [\"4.5\"], \"resource\": \"Quality Assurance Officer\"},\n",
    " {\"id\": \"4.7\", \"name\": \"Draft Report to Client\", \"duration\": 2, \"dependencies\": [\"4.6\"], \"resource\": \"Project Manager\"},\n",
    " {\"id\": \"4.8\", \"name\": \"Update Report Per Feedback\", \"duration\": 2, \"dependencies\": [\"4.7\"], \"resource\": \"Project Manager\"},\n",
    " {\"id\": \"4.9\", \"name\": \"Enter Results into Database\", \"duration\": 2, \"dependencies\": [\"4.8\"], \"resource\": \"Administrative Support Specialist\"},\n",
    "]\n",
    "\n",
    "ceramics_template = [\n",
    " # ------ Sample Management ------\n",
    " {\"id\": \"1.1\", \"name\": \"Receive and Log Samples\", \"duration\": 4, \"dependencies\": [], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.2\", \"name\": \"Assign Unique Identifiers\", \"duration\": 2, \"dependencies\": [\"1.1\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.3\", \"name\": \"Photograph Initial Condition\", \"duration\": 2, \"dependencies\": [\"1.2\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"1.4\", \"name\": \"Write Analysis Plan\", \"duration\": 3, \"dependencies\": [\"1.3\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"1.5\", \"name\": \"Store Samples Appropriately\", \"duration\": 1, \"dependencies\": [\"1.4\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.6\", \"name\": \"Document Chain of Custody\", \"duration\": 1, \"dependencies\": [\"1.5\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " # ------ Sample Preparation ------\n",
    " {\"id\": \"2.1\", \"name\": \"Cut Subsamples for Mounting\", \"duration\": 3, \"dependencies\": [\"1.6\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.2\", \"name\": \"Cut Subsamples for ICP\", \"duration\": 3, \"dependencies\": [\"1.6\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.3\", \"name\": \"Clean Cut Subsamples\", \"duration\": 2, \"dependencies\": [\"2.1\",\"2.2\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.4\", \"name\": \"Mount Subsample in Epoxy\", \"duration\": 3, \"dependencies\": [\"2.3\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.5\", \"name\": \"Crush & Sieve for Powder\", \"duration\": 4, \"dependencies\": [\"2.3\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.6\", \"name\": \"Grind & Polish Mounted Subsmpl\", \"duration\": 4, \"dependencies\": [\"2.4\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"2.7\", \"name\": \"Digest Sample (Acid/MW)\", \"duration\": 4, \"dependencies\": [\"2.3\"], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " {\"id\": \"2.8\", \"name\": \"Prep ICP Standards/Blanks\", \"duration\": 2, \"dependencies\": [], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " {\"id\": \"2.9\", \"name\": \"Coat Sample for SEM/EBSD\", \"duration\": 2, \"dependencies\": [\"2.6\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.10\",\"name\": \"Label & Catalog Prepared Smpls\", \"duration\": 2, \"dependencies\": [\"2.5\",\"2.3\",\"2.6\",\"2.7\",\"2.9\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " # ------ Sample Analysis ------\n",
    " {\"id\": \"3.1\", \"name\": \"FTIR for Composition\", \"duration\": 4, \"dependencies\": [\"2.10\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"3.2\", \"name\": \"Raman for Crystalline Phases\", \"duration\": 4, \"dependencies\": [\"2.10\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"3.3\", \"name\": \"SEM Imaging (Microstructure)\", \"duration\": 6, \"dependencies\": [\"2.10\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"3.4\", \"name\": \"XRD for Phase Info\", \"duration\": 5, \"dependencies\": [\"2.10\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"3.5\", \"name\": \"TGA for Thermal Stability\", \"duration\": 5, \"dependencies\": [\"2.10\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"3.6\", \"name\": \"DSC for Thermal Transitions\", \"duration\": 5, \"dependencies\": [\"2.10\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"3.7\", \"name\": \"Microindentation (Knoop)\", \"duration\": 6, \"dependencies\": [\"2.10\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"3.8\", \"name\": \"SEM-EDS for Elemental Comp\", \"duration\": 6, \"dependencies\": [\"2.10\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"3.9\", \"name\": \"ICP-OES/ICP-MS for Trace Elem\", \"duration\": 6, \"dependencies\": [\"2.10\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " # ------ Data Analysis ------\n",
    " {\"id\": \"4.1\", \"name\": \"Compile Analytical Results\", \"duration\": 2, \"dependencies\": [\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\",\"3.8\",\"3.9\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"4.2\", \"name\": \"Interpret Data (Ceramic Props)\", \"duration\": 6, \"dependencies\": [\"4.1\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"4.3\", \"name\": \"Cross-Validate Across Techniques\", \"duration\": 6, \"dependencies\": [\"4.2\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"4.4\", \"name\": \"Prepare Final Figures\", \"duration\": 3, \"dependencies\": [\"4.3\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"4.5\", \"name\": \"Perform Peer Review\", \"duration\": 2, \"dependencies\": [\"4.4\"], \"resource\": \"Materials Scientist (Ceramics)\"},\n",
    " {\"id\": \"4.6\", \"name\": \"QA Review of Data/Results\", \"duration\": 2, \"dependencies\": [\"4.5\"], \"resource\": \"Quality Assurance Officer\"},\n",
    " {\"id\": \"4.7\", \"name\": \"Draft Report to Client\", \"duration\": 2, \"dependencies\": [\"4.6\"], \"resource\": \"Project Manager\"},\n",
    " {\"id\": \"4.8\", \"name\": \"Update Report Per Feedback\", \"duration\": 2, \"dependencies\": [\"4.7\"], \"resource\": \"Project Manager\"},\n",
    " {\"id\": \"4.9\", \"name\": \"Enter Results into Database\", \"duration\": 2, \"dependencies\": [\"4.8\"], \"resource\": \"Administrative Support Specialist\"},\n",
    "]\n",
    "\n",
    "composites_template = [\n",
    " # ------ Sample Management ------\n",
    " {\"id\": \"1.1\", \"name\": \"Receive and Log Samples\", \"duration\": 4, \"dependencies\": [], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.2\", \"name\": \"Assign Unique Identifiers\", \"duration\": 2, \"dependencies\": [\"1.1\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.3\", \"name\": \"Photograph Initial Condition\", \"duration\": 2, \"dependencies\": [\"1.2\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"1.4\", \"name\": \"Write Analysis Plan\", \"duration\": 3, \"dependencies\": [\"1.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"1.5\", \"name\": \"Store Samples Appropriately\", \"duration\": 1, \"dependencies\": [\"1.4\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.6\", \"name\": \"Document Chain of Custody\", \"duration\": 1, \"dependencies\": [\"1.5\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " # ------ Sample Preparation ------\n",
    " {\"id\": \"2.1\", \"name\": \"Section and Polish\", \"duration\": 3, \"dependencies\": [\"1.6\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"2.2\", \"name\": \"Embed Samples in Resin\", \"duration\": 3, \"dependencies\": [\"1.6\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.3\", \"name\": \"Label & Catalog Prepared Smpls\", \"duration\": 3, \"dependencies\": [\"1.6\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " # ------ Sample Analysis ------\n",
    " {\"id\": \"3.1\", \"name\": \"FTIR for Matrix\", \"duration\": 4, \"dependencies\": [\"2.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.2\", \"name\": \"Raman for Fibers\", \"duration\": 4, \"dependencies\": [\"2.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.3\", \"name\": \"Raman for Matrix\", \"duration\": 4, \"dependencies\": [\"2.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.4.1\",\"name\": \"SEM-EDS Fiber Comp\", \"duration\": 6, \"dependencies\": [\"2.3\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"3.4.2\",\"name\": \"SEM-EDS Matrix Comp\", \"duration\": 6, \"dependencies\": [\"2.3\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"3.5\", \"name\": \"TGA (Thermal Stability/Filler)\", \"duration\": 5, \"dependencies\": [\"2.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.6\", \"name\": \"DSC (Polymer Transition)\", \"duration\": 5, \"dependencies\": [\"2.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.7\", \"name\": \"PYGCMS (Matrix Composition)\", \"duration\": 6, \"dependencies\": [\"2.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.8\", \"name\": \"ICP-OES/ICP-MS (Elements)\", \"duration\": 8, \"dependencies\": [\"2.3\"], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " {\"id\": \"3.9\", \"name\": \"Fiber Analysis (Optical/SEM)\", \"duration\": 8, \"dependencies\": [\"2.3\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"3.10\",\"name\": \"Measure Density (Pycnometer)\", \"duration\": 3, \"dependencies\": [\"2.3\"], \"resource\": \"Laboratory Technician\"},\n",
    " # ------ Data Analysis ------\n",
    " {\"id\": \"4.1\", \"name\": \"Cross-Validate Composition\", \"duration\": 6, \"dependencies\": [\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\",\"3.8\",\"3.9\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"4.2\", \"name\": \"Prepare Final Figures\", \"duration\": 3, \"dependencies\": [\"4.1\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"4.3\", \"name\": \"Perform Peer Review\", \"duration\": 2, \"dependencies\": [\"4.2\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"4.4\", \"name\": \"QA Review of Data/Results\", \"duration\": 1, \"dependencies\": [\"4.3\"], \"resource\": \"Quality Assurance Officer\"},\n",
    " {\"id\": \"4.5\", \"name\": \"Draft Report to Client\", \"duration\": 2, \"dependencies\": [\"4.4\"], \"resource\": \"Project Manager\"},\n",
    " {\"id\": \"4.6\", \"name\": \"Update Report Per Feedback\", \"duration\": 2, \"dependencies\": [\"4.5\"], \"resource\": \"Project Manager\"},\n",
    " {\"id\": \"4.7\", \"name\": \"Enter Results into Database\", \"duration\": 2, \"dependencies\": [\"4.6\"], \"resource\": \"Administrative Support Specialist\"},\n",
    "]\n",
    "\n",
    "polymers_template = [\n",
    " # ------ Sample Management ------\n",
    " {\"id\": \"1.1\", \"name\": \"Receive and Log Samples\", \"duration\": 4, \"dependencies\": [], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.2\", \"name\": \"Assign Unique Identifiers\", \"duration\": 2, \"dependencies\": [\"1.1\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.3\", \"name\": \"Photograph Initial Condition\", \"duration\": 2, \"dependencies\": [\"1.2\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"1.4\", \"name\": \"Write Analysis Plan\", \"duration\": 3, \"dependencies\": [\"1.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"1.5\", \"name\": \"Store Samples Appropriately\", \"duration\": 1, \"dependencies\": [\"1.4\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " {\"id\": \"1.6\", \"name\": \"Document Chain of Custody\", \"duration\": 1, \"dependencies\": [\"1.5\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " # ------ Sample Preparation ------\n",
    " {\"id\": \"2.1\", \"name\": \"Cut Subsamples for Mounting\", \"duration\": 3, \"dependencies\": [], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.2\", \"name\": \"Cut Subsamples for ICP\", \"duration\": 3, \"dependencies\": [], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.3\", \"name\": \"Clean Cut Subsamples\", \"duration\": 2, \"dependencies\": [\"2.1\",\"2.2\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.4\", \"name\": \"Mount Subsample in Epoxy\", \"duration\": 3, \"dependencies\": [\"2.1\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.5\", \"name\": \"Grind & Polish Mounted Subsmpl\", \"duration\": 4, \"dependencies\": [\"2.4\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"2.6\", \"name\": \"Digest Sample (Acid/MW)\", \"duration\": 4, \"dependencies\": [\"2.3\"], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " {\"id\": \"2.7\", \"name\": \"Prep ICP Standards/Blanks\", \"duration\": 2, \"dependencies\": [], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " {\"id\": \"2.8\", \"name\": \"Coat Sample for SEM/EBSD\", \"duration\": 2, \"dependencies\": [\"2.5\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"2.9\", \"name\": \"Label & Catalog Prepared Smpls\", \"duration\": 2, \"dependencies\": [\"2.2\",\"2.5\",\"2.6\",\"2.8\"], \"resource\": \"Administrative Support Specialist\"},\n",
    " # ------ Sample Analysis ------\n",
    " {\"id\": \"3.1\", \"name\": \"Optical Microscope\", \"duration\": 2, \"dependencies\": [\"2.5\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.2\", \"name\": \"SEM Imaging\", \"duration\": 4, \"dependencies\": [\"2.8\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"3.3\", \"name\": \"SEM-EDS (Polymer Comp)\", \"duration\": 4, \"dependencies\": [\"3.2\"], \"resource\": \"Advanced Imaging Specialist\"},\n",
    " {\"id\": \"3.4\", \"name\": \"FTIR for Composition\", \"duration\": 4, \"dependencies\": [\"2.5\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.5\", \"name\": \"Raman for Composition\", \"duration\": 4, \"dependencies\": [\"2.5\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.6\", \"name\": \"Measure Density (Pycnometer)\", \"duration\": 3, \"dependencies\": [\"2.3\"], \"resource\": \"Laboratory Technician\"},\n",
    " {\"id\": \"3.7\", \"name\": \"Hardness Microindentation\", \"duration\": 3, \"dependencies\": [\"2.5\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.8\", \"name\": \"TGA (Thermal Stability/Filler)\", \"duration\": 5, \"dependencies\": [\"2.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.9\", \"name\": \"DSC (Polymer Transition)\", \"duration\": 5, \"dependencies\": [\"2.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.10\",\"name\": \"PYGCMS (Matrix)\", \"duration\": 6, \"dependencies\": [\"2.3\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"3.11\",\"name\": \"ICP-MS/ICP-OES\", \"duration\": 8, \"dependencies\": [\"2.6\",\"2.7\"], \"resource\": \"Analytical Instrument Specialist\"},\n",
    " # ------ Data Analysis ------\n",
    " {\"id\": \"4.1\", \"name\": \"Cross-Validate Composition\", \"duration\": 6, \"dependencies\": [\"3.3\",\"3.4\",\"3.5\",\"3.6\",\"3.7\",\"3.8\",\"3.9\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"4.2\", \"name\": \"Prepare Final Figures\", \"duration\": 3, \"dependencies\": [\"4.1\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"4.3\", \"name\": \"Perform Peer Review\", \"duration\": 2, \"dependencies\": [\"4.2\"], \"resource\": \"Materials Scientist (Composites)\"},\n",
    " {\"id\": \"4.4\", \"name\": \"QA Review of Data/Results\", \"duration\": 1, \"dependencies\": [\"4.3\"], \"resource\": \"Quality Assurance Officer\"},\n",
    " {\"id\": \"4.5\", \"name\": \"Draft Report to Client\", \"duration\": 2, \"dependencies\": [\"4.4\"], \"resource\": \"Project Manager\"},\n",
    " {\"id\": \"4.6\", \"name\": \"Update Report Per Feedback\", \"duration\": 2, \"dependencies\": [\"4.5\"], \"resource\": \"Project Manager\"},\n",
    " {\"id\": \"4.7\", \"name\": \"Enter Results into Database\", \"duration\": 2, \"dependencies\": [\"4.6\"], \"resource\": \"Administrative Support Specialist\"},\n",
    "]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    " logging.info(\"Starting capacity analysis\")\n",
    " \n",
    " templates = [metals_template, ceramics_template, composites_template, polymers_template]\n",
    " \n",
    " resource_ranges = {\n",
    " \"Administrative Support Specialist\": (1, 4),\n",
    " \"Laboratory Technician\": (1, 3),\n",
    " \"Materials Scientist (Metals)\": (1, 2),\n",
    " \"Materials Scientist (Ceramics)\": (1, 2),\n",
    " \"Materials Scientist (Composites)\": (1, 2),\n",
    " \"Advanced Imaging Specialist\": (1, 2),\n",
    " \"Analytical Instrument Specialist\": (1, 2),\n",
    " \"Quality Assurance Officer\": (1, 1),\n",
    " \"Project Manager\": (1, 1)\n",
    " }\n",
    " \n",
    " sample_ranges = {\n",
    " \"metals\": (0, 20),\n",
    " \"ceramics\": (0, 20),\n",
    " \"composites\": (0, 15),\n",
    " \"polymers\": (0, 15)\n",
    " }\n",
    " \n",
    " step_sizes = {\n",
    " \"metals\": 4,\n",
    " \"ceramics\": 4,\n",
    " \"composites\": 3,\n",
    " \"polymers\": 3,\n",
    " **{r: 1 for r in resource_ranges.keys()}\n",
    " }\n",
    " \n",
    " resource_unit_costs = {\n",
    " \"Administrative Support Specialist\": 75,\n",
    " \"Laboratory Technician\": 100,\n",
    " \"Materials Scientist (Metals)\": 150,\n",
    " \"Materials Scientist (Ceramics)\": 150,\n",
    " \"Materials Scientist (Composites)\": 150,\n",
    " \"Advanced Imaging Specialist\": 150,\n",
    " \"Analytical Instrument Specialist\": 125,\n",
    " \"Quality Assurance Officer\": 125,\n",
    " \"Project Manager\": 175\n",
    " }\n",
    " \n",
    " try:\n",
    " results = run_capacity_analysis(\n",
    " templates=templates,\n",
    " resource_ranges=resource_ranges,\n",
    " sample_ranges=sample_ranges,\n",
    " resource_unit_costs=resource_unit_costs,\n",
    " step_sizes=step_sizes,\n",
    " output_file=\"capacity_results.csv\"\n",
    " )\n",
    " logging.info(\"Analysis completed successfully\")\n",
    " \n",
    " except Exception as e:\n",
    " logging.error(f\"Analysis failed: {str(e)}\")"
   ],
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 51 (1499599134.py, line 52)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[3], line 52\u001B[1;36m\u001B[0m\n\u001B[1;33m    for task in template:\u001B[0m\n\u001B[1;37m    ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m expected an indented block after 'for' statement on line 51\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
